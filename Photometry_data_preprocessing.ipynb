{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2Si_ELX5PB1",
    "tags": []
   },
   "source": [
    "# Photometry data preprocessing\n",
    "\n",
    "This notebook shows methods for preprocessing fiber photometry data. The preprocessing consists of the following steps:\n",
    "\n",
    "1. Lowpass filtering to reduce noise.\n",
    "\n",
    "2. Correction for photobleaching, i.e. the slow decreace in the fluorescence signal over time.  Two different methods are shown (i) subtraction of a double exponential fit (ii) highpass filtering with a very low cutoff frequency.\n",
    "\n",
    "2. Movement correction by subtracting a linear fit of the movement control channel.\n",
    "\n",
    "4. Conversion of the signal to dF/F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHB9AKgh5PB3"
   },
   "source": [
    "Import the standard python modules needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS3Cv-JI5PB4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as  np\n",
    "import pylab as plt\n",
    "from scipy.signal import medfilt, butter, filtfilt\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "\n",
    "#set default plot properties\n",
    "plt.rcParams['figure.figsize'] = [14, 12] # Make default figure size larger.\n",
    "plt.rcParams['axes.xmargin'] = 0          # Make default margin on x axis zero.\n",
    "plt.rcParams['axes.labelsize'] = 12     #Set default axes label size\n",
    "plt.rcParams['axes.titlesize']=15\n",
    "plt.rcParams['axes.titleweight']='heavy'\n",
    "plt.rcParams['ytick.labelsize']= 10\n",
    "plt.rcParams['xtick.labelsize']= 10\n",
    "plt.rcParams['legend.fontsize']=12\n",
    "plt.rcParams['legend.markerscale']=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6Pwu_m45PB5"
   },
   "source": [
    "Import the photometry data and times of reward cues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dObRhanv5PB6",
    "outputId": "68991816-79ad-433a-9214-2c4b5b3417b8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = '//'\n",
    "filename = '.csv'\n",
    "#今回のデータはcsvなのでコメントアウトする\n",
    "#data = import_ppd(os.path.join(data_folder, data_filename))\n",
    "\n",
    "import pandas as pd\n",
    "my_data_path = os.path.join(folder_path, filename)\n",
    "df = pd.read_csv(my_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkbX4AG75PB6"
   },
   "source": [
    "Extract the raw dLight and TdTomato signals, session time, and sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s62N2_CM5PB7"
   },
   "outputs": [],
   "source": [
    "#⭐︎⭐︎⭐︎⭐︎⭐︎サンプリングレートは30⭐︎⭐︎⭐︎⭐︎⭐︎⭐︎\n",
    "ch470_raw = df['CH1-470'].values\n",
    "ch410_raw = df['CH1-410'].values\n",
    "time_seconds = df['TimeStamp'].values / 1000\n",
    "sampling_rate = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co_Hi4bV5PB7"
   },
   "source": [
    "# Raw signals\n",
    "\n",
    "Let's take a look at the raw  and isosbetic signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XGvcRDW-5PB8",
    "outputId": "58d38b98-b86b-40d0-f80f-8e95820bcfb0"
   },
   "outputs": [],
   "source": [
    "# Plot signals\n",
    "\n",
    "fig,ax1=plt.subplots()  # create a plot to allow for dual y-axes plotting\n",
    "plot1=ax1.plot(time_seconds, ch470_raw, 'g', label='ch470') #plot dLight on left y-axis\n",
    "ax2=plt.twinx()# create a right y-axis, sharing x-axis on the same plot\n",
    "plot2=ax2.plot(time_seconds, ch410_raw, 'r', label='ch410') # plot TdTomato on right y-axis\n",
    "\n",
    "#ax1.set_ylim(1.25, 1.65)\n",
    "#ax2.set_ylim(1.35, 1.75)\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 Signal (V)', color='g')\n",
    "ax2.set_ylabel('ch410 Signal (V)', color='r')\n",
    "ax1.set_title('Raw signals')\n",
    "\n",
    "lines = plot1 + plot2 #+reward_ticks #line handle for legend\n",
    "labels = [l.get_label() for l in lines]  #get legend labels\n",
    "legend = ax1.legend(lines, labels, loc='upper right', bbox_to_anchor=(0.98, 0.93)) #add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM3imC7A5PB8"
   },
   "source": [
    "# Denoising\n",
    "\n",
    "We lowpass filter the signals to reduce high frequency noise, using a zero phase filter with a 10Hz cutoff frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XCZmClzH5PB9",
    "outputId": "115ce3b7-a53f-426d-99d2-8d1e88e0e839"
   },
   "outputs": [],
   "source": [
    "#ナイキスト周波数は、サンプリングレートの半分の値になる\n",
    "#Lowpass filter - zero phase filtering (with filtfilt) is used to avoid distorting the signal.\n",
    "#ここの第二引数がローパスフィルターの値になる\n",
    "b,a = butter(2, 10, btype='low', fs=sampling_rate)\n",
    "ch470_denoised = filtfilt(b,a, ch470_raw)\n",
    "ch410_denoised = filtfilt(b,a, ch410_raw)\n",
    "\n",
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_denoised, 'g', label='ch470 denoised')\n",
    "ax2=plt.twinx()\n",
    "plot2=ax2.plot(time_seconds, ch410_denoised, 'r', label='ch410 denoised')\n",
    "\n",
    "#ax1.set_ylim(1.25, 1.65)\n",
    "#ax2.set_ylim(1.35, 1.75)\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 Signal (V)', color='g')\n",
    "ax2.set_ylabel('ch410 Signal (V)', color='r')\n",
    "ax1.set_title('Denoised signals')\n",
    "\n",
    "lines = plot1+plot2\n",
    "labels = [l.get_label() for l in lines]  \n",
    "legend = ax1.legend(lines, labels, loc='upper right', bbox_to_anchor=(0.98, 0.92)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG5v1ssN5PB9"
   },
   "source": [
    "Let's zoom in on the x axis to see how the lowpass filtering has smoothed the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fI-XLC2z5PB9",
    "outputId": "f3a23abb-cefd-428c-8438-1d4731f3fe0e"
   },
   "outputs": [],
   "source": [
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_raw, color='g', alpha=0.3, label='ch470 raw')\n",
    "ax2=plt.twinx()\n",
    "plot2=ax2.plot(time_seconds, ch410_raw, color='r', alpha=0.3, label='ch410 raw')\n",
    "plot3=ax1.plot(time_seconds, ch470_denoised, color='g', label='ch470 denoised')\n",
    "plot4=ax2.plot(time_seconds, ch410_denoised, color='r', label='ch410 denoised')\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 Signal (V)', color='g')\n",
    "ax2.set_ylabel('ch410 Signal (V)', color='r')\n",
    "ax1.set_title('Denoised signals')\n",
    "\n",
    "lines = plot1+plot2 + plot3 + plot4\n",
    "labels = [l.get_label() for l in lines]\n",
    "legend = ax1.legend(lines, labels, loc='upper right', bbox_to_anchor=(0.93, 0.99))\n",
    "ax1.set_xlim(1000, 1060) # 60 sec window\n",
    "#ax1.set_ylim(1.4, 1.625)\n",
    "#ax2.set_ylim(1.4, 1.625);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7HT1ttc5PB-",
    "tags": []
   },
   "source": [
    "# Photobleaching correction\n",
    "\n",
    "Now lets remove the influence of photobleaching.\n",
    "\n",
    "### Method: Double Exponential Fit\n",
    "\n",
    "One way of removing the influence of bleaching is to fit an exponential decay to the data and subtract this exponential fit from the signal (note, some groups divide the signal by the baseline rather than subtracting the baseline, see Fiber Photometry Primer for more discussion). In practice we find that a double exponential fit is preferable to a single exponential fit because there are typically multiple sources of fluorescence that contribute to the bleaching (e.g. autofluorescence from fiber, autofluorescence from brain tissue, and flurophore fluorescence), which may bleach at different rates, so a single exponential fit can be overly restrictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sN_9FkIc5PB-",
    "outputId": "41283306-8a4b-4751-d6af-823b52928843",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The double exponential curve we are going to fit.\n",
    "def double_exponential(t, const, amp_fast, amp_slow, tau_slow, tau_multiplier):\n",
    "    '''Compute a double exponential function with constant offset.\n",
    "    Parameters:\n",
    "    t       : Time vector in seconds.\n",
    "    const   : Amplitude of the constant offset.\n",
    "    amp_fast: Amplitude of the fast component.\n",
    "    amp_slow: Amplitude of the slow component.\n",
    "    tau_slow: Time constant of slow component in seconds.\n",
    "    tau_multiplier: Time constant of fast component relative to slow.\n",
    "    '''\n",
    "    tau_fast = tau_slow*tau_multiplier\n",
    "    return const+amp_slow*np.exp(-t/tau_slow)+amp_fast*np.exp(-t/tau_fast)\n",
    "\n",
    "# Fit curve to ch470 signal.\n",
    "max_sig = np.max(ch470_denoised)\n",
    "inital_params = [max_sig/2, max_sig/4, max_sig/4, 3600, 0.1]\n",
    "bounds = ([0      , 0      , 0      , 600  , 0],\n",
    "          [max_sig, max_sig, max_sig, 36000, 1])\n",
    "ch470_parms, parm_cov = curve_fit(double_exponential, time_seconds, ch470_denoised,\n",
    "                                  p0=inital_params, bounds=bounds, maxfev=1000)\n",
    "ch470_expfit = double_exponential(time_seconds, *ch470_parms)\n",
    "\n",
    "# Fit curve to ch410 signal.\n",
    "max_sig = np.max(ch410_denoised)\n",
    "inital_params = [max_sig/2, max_sig/4, max_sig/4, 3600, 0.1]\n",
    "bounds = ([0      , 0      , 0      , 600  , 0],\n",
    "          [max_sig, max_sig, max_sig, 36000, 1])\n",
    "ch410_parms, parm_cov = curve_fit(double_exponential, time_seconds, ch410_denoised,\n",
    "                                  p0=inital_params, bounds=bounds, maxfev=1000)\n",
    "ch410_expfit = double_exponential(time_seconds, *ch410_parms)\n",
    "\n",
    "#plot fits over denoised data\n",
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_denoised, 'g', label='dLight')\n",
    "plot3=ax1.plot(time_seconds, ch470_expfit, color='k', linewidth=1.5, label='Exponential fit')\n",
    "ax2=plt.twinx()\n",
    "plot2=ax2.plot(time_seconds, ch410_denoised, color='r', label='TdTomato')\n",
    "plot4=ax2.plot(time_seconds, ch410_expfit,color='k', linewidth=1.5)\n",
    "\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 Signal (V)', color='g')\n",
    "ax2.set_ylabel('ch410 Signal (V)', color='r')\n",
    "ax1.set_title('Denoised signals with double exponential fits')\n",
    "\n",
    "lines = plot1 + plot2 + plot3\n",
    "labels = [l.get_label() for l in lines]\n",
    "legend = ax1.legend(lines, labels, loc='upper right');\n",
    "#ax1.set_ylim(1.27, 1.62)\n",
    "#ax2.set_ylim(1.35, 1.7);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynt53WUX5PB-"
   },
   "source": [
    "Now we subtract the exponential fits from the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x1xskUwz5PB-",
    "outputId": "90322f9f-b8a7-452f-ec67-a32c65e317c8"
   },
   "outputs": [],
   "source": [
    "ch470_detrended = ch470_denoised - ch470_expfit\n",
    "ch410_detrended = ch410_denoised - ch410_expfit\n",
    "\n",
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_detrended, 'g', label='dLight')\n",
    "ax2=plt.twinx()\n",
    "plot2=ax2.plot(time_seconds, ch410_detrended, color='r', label='TdTomato')\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 Signal (V)', color='g')\n",
    "ax2.set_ylabel('ch410 Signal (V)', color='r')\n",
    "ax1.set_title('Bleaching Correction by Double Exponential Fit')\n",
    "\n",
    "lines = plot1+plot2\n",
    "labels = [l.get_label() for l in lines]\n",
    "legend = ax1.legend(lines, labels, loc='upper right');\n",
    "#ax1.set_ylim(-0.18, 0.12)\n",
    "#ax2.set_ylim(-0.1, 0.2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcCnx5QY5PB_"
   },
   "source": [
    "# Motion correction\n",
    "\n",
    "We now do motion correction by finding the best linear fit of the isosbetic signal to the raw signal and subtracting this estimated motion component from the raw signal.  We will use the data that was bleaching corrected using the double exponential fit as this is less likely to remove meaningful slow variation in the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H1YkpU7g5PB_",
    "outputId": "f1d21d00-b4d7-4ded-f2be-75c547ba0596"
   },
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = linregress(x=ch410_detrended, y=ch470_detrended)\n",
    "\n",
    "plt.scatter(ch410_detrended[::5], ch470_detrended[::5],alpha=0.1, marker='.')\n",
    "x = np.array(plt.xlim())\n",
    "plt.plot(x, intercept+slope*x)\n",
    "plt.xlabel('ch410')\n",
    "plt.ylabel('ch470')\n",
    "plt.title('ch410 - ch470 correlation.')\n",
    "\n",
    "print('Slope    : {:.3f}'.format(slope))\n",
    "print('R-squared: {:.3f}'.format(r_value**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzcYEjZE5PB_"
   },
   "source": [
    "We can see that as expected the signals have a positive correlation due to the common contribution of movement to each.  \n",
    "We now calculate the estimated motion component of the raw signal and subtract to get the motion corrected signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Siq-Zl795PB_",
    "outputId": "258a4a46-73fc-4385-ac5a-e6d8a6ad3221"
   },
   "outputs": [],
   "source": [
    "ch470_est_motion = intercept + slope * ch410_detrended\n",
    "ch470_corrected = ch470_detrended - ch470_est_motion\n",
    "\n",
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_detrended, 'b' , label='ch470 - pre motion correction', alpha=0.5)\n",
    "plot3=ax1.plot(time_seconds, ch470_corrected, 'g', label='ch470 - motion corrected', alpha=0.5)\n",
    "plot4=ax1.plot(time_seconds, ch470_est_motion - 0.05, 'y', label='estimated motion')\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 Signal (V)', color='g')\n",
    "ax1.set_title('Motion Correction')\n",
    "\n",
    "lines = plot1+plot3+plot4\n",
    "labels = [l.get_label() for l in lines]\n",
    "legend = ax1.legend(lines, labels, loc='upper right', bbox_to_anchor=(0.95, 0.98))\n",
    "#ax1.set_xlim(1000, 1060)  # 60 sec window\n",
    "#ax1.set_ylim(-0.075, 0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6uOpUmt5PB_"
   },
   "source": [
    "# Normalisation\n",
    "\n",
    "### Method 1: dF/F\n",
    "\n",
    "To compute dF/F we divide the signal changes (dF) by the baseline fluorescence (F) and multiply by 100 to convert to percent. The dF is just the motion corrected signal plotted above.  The baseline fluorescence F changes over the course of the session due to photobleaching, and is just the baseline we estimated with our double exponential fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JmGOWC345PCA",
    "outputId": "ebff9903-4639-4495-b114-6c130e8a190f"
   },
   "outputs": [],
   "source": [
    "ch470_dF_F = 100*ch470_corrected/ch470_expfit\n",
    "\n",
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_dF_F, 'g', label='ch470 dF/F')\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('ch470 dF/F (%)')\n",
    "ax1.set_title('ch470 dF/F')\n",
    "\n",
    "lines = plot1 \n",
    "labels = [l.get_label() for l in lines]\n",
    "legend = ax1.legend(lines, labels, loc='upper right', bbox_to_anchor=(0.95, 0.98))\n",
    "\n",
    "ax1.set_xlim(1000, 1060)\n",
    "#ax1.set_ylim(-3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WKJ-hhi5PCA"
   },
   "source": [
    "### Method 2: Z-scoring\n",
    "\n",
    "we can normalise the data by z-scoring each session - i.e. subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PHU30kNb5PCA",
    "outputId": "26d3e441-251c-4735-c5cb-599347ffe8e1"
   },
   "outputs": [],
   "source": [
    "ch470_zscored = (ch470_corrected-np.mean(ch470_corrected))/np.std(ch470_corrected)\n",
    "\n",
    "\n",
    "fig,ax1=plt.subplots()\n",
    "plot1=ax1.plot(time_seconds, ch470_zscored, 'g', label='CH470 z-score')\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('CH470 z-score')\n",
    "ax1.set_title('CH470 z-scored')\n",
    "\n",
    "lines = plot1\n",
    "labels = [l.get_label() for l in lines]\n",
    "legend = ax1.legend(lines, labels, loc='upper right', bbox_to_anchor=(0.95, 0.98))\n",
    "\n",
    "ax1.set_xlim(1740, 2040)\n",
    "ax1.set_ylim(-4, 6);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IixzpaI5PCA"
   },
   "source": [
    "(c) Copyright Thomas Akam & Lauren Burgeno 2019 - 2023.  Released under the [GPL3 Licence](https://www.gnu.org/licenses/gpl-3.0.en.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9aylhuQjkJa",
    "outputId": "df6e9036-8530-4b76-f680-2d4162a94069"
   },
   "outputs": [],
   "source": [
    "processed_df = pd.DataFrame({\n",
    "    'Time_seconds': time_seconds,\n",
    "    'dF_F (%)': ch470_dF_F,\n",
    "    'Z_score': ch470_zscored\n",
    "})\n",
    "\n",
    "output_filename = f\"waltonlab_{filename}\"\n",
    "output_path = os.path.join(folder_path, output_filename)\n",
    "processed_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
